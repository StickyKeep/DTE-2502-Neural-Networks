{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "### **ELI5**:\n",
    "\n",
    "Imagine you're hiking on a mountain and it's super foggy. You want to get to the bottom of the mountain, but you can't see very far because of the fog. You decide to always walk in the direction where the ground goes down the steepest. Every time you take a step, you feel the ground with your feet and choose the direction that goes downhill the most. By doing this, step by step, you eventually reach the bottom of the mountain.\n",
    "\n",
    "In this analogy:\n",
    "- The mountain is like a function we want to minimize.\n",
    "- You are trying to find the quickest way to the bottom.\n",
    "- The direction you choose to walk in each step is based on where the ground goes down the most, which is like the \"gradient\" or slope.\n",
    "\n",
    "### Bit more advanced\n",
    "\n",
    "**Gradient Descent** is a fundamental optimization algorithm used to find the minimum of a function. It's the backbone of many machine learning algorithms, especially when it comes to training models.\n",
    "\n",
    "Here's the breakdown:\n",
    "\n",
    "1. **Gradient**: The gradient of a function at a point is a vector that points in the direction of the steepest increase of the function. For a function with many variables, it's made up of partial derivatives, each showing how the function changes as we adjust one of the variables while keeping the others constant.\n",
    "\n",
    "2. **Descent**: Since we're looking to minimize the function (like reducing the error in predictions), we want to move in the opposite direction of the gradient. This is the \"descent\" part. We're descending down the function to find its lowest point.\n",
    "\n",
    "The Gradient Descent algorithm works like this:\n",
    "\n",
    "- Start with an initial guess for the solution (e.g., initial weights in a neural network).\n",
    "- Compute the gradient of the function using the current guess.\n",
    "- Update the solution by taking a step in the opposite direction of the gradient. The size of the step is determined by a parameter called the learning rate.\n",
    "- Repeat this process until the solution doesn't change much between steps or until a set number of steps.\n",
    "\n",
    "The main difference between Gradient Descent and Stochastic Gradient Descent is in how the gradient is computed. In Gradient Descent, the gradient is computed using all data points (which can be slow for large datasets), while in Stochastic Gradient Descent, the gradient is computed using a single or a small batch of data points, making it faster but also introducing some randomness.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Gradient Descent\n",
    "### **ELI5**\n",
    "\n",
    "Imagine you're at the top of a hilly park and you have a ball. You want to roll the ball down to the lowest point of the park. Instead of looking at the whole park to find the quickest path down, you just look at the ground right in front of you. You give the ball a little push in the direction that seems to go downwards. You keep doing this, giving the ball little pushes, and watching which way it goes down. After several little pushes, the ball eventually reaches the lowest point.\n",
    "\n",
    "In this analogy:\n",
    "- The hilly park is like a function we want to minimize.\n",
    "- The ball is our current guess or solution.\n",
    "- The little pushes are small steps we take to adjust our solution to make it better.\n",
    "\n",
    "### **Or in another words:**\n",
    "\n",
    "Stochastic Gradient Descent (SGD) is an optimization algorithm commonly used in machine learning, especially for training deep neural networks.\n",
    "\n",
    "Let's break it down:\n",
    "\n",
    "1. **Gradient**: This refers to the slope or direction of the steepest increase of a function. For a multi-variable function, it's a vector of partial derivatives. In simpler terms, the gradient points in the direction where the function is increasing the fastest.\n",
    "2. **Descent**: This means we want to go in the opposite direction of the gradient. Why? Because we usually want to minimize a function, like the error in a machine learning model. By moving opposite to the gradient, we're heading towards the minimum.\n",
    "3. **Stochastic**: In the context of SGD, this means that instead of using the entire dataset to compute the gradient (which can be computationally expensive), we use just one or a small batch of data points. This introduces randomness (hence \"stochastic\"), as the direction of the gradient can vary based on which data points are chosen.\n",
    "\n",
    "The process is iterative:\n",
    "- Start with an initial guess for the solution (like initial weights in a neural network).\n",
    "- Randomly pick a data point (or a small batch) from the dataset.\n",
    "- Compute the gradient using that data point.\n",
    "- Update the solution by moving a small step in the opposite direction of the gradient.\n",
    "- Repeat until convergence or for a set number of iterations.\n",
    "\n",
    "The main advantage of SGD over traditional gradient descent is speed. Because it uses only a subset of the data at each step, it can make progress and adjust the solution without having to process the entire dataset. However, because of the stochastic nature, it can be noisier and might not always take the most direct path to the minimum, but with the right parameters, it can converge to a good solution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic example in Python\n",
    "We'll try to find the minimum of the quadratic function f(x)=x**2 using Stochastic Gradient Descent (SGD).\n",
    "\n",
    "The true minimum of this function is at x=0\n",
    "\n",
    "Here's how the SGD process would look:\n",
    "\n",
    "* Initialization: Start with a random guess for x.\n",
    "* Gradient Calculation: f'(x) = 2x\n",
    "* Update Rule: Update x by subtracting a fraction (learning rate) of the gradient.\n",
    "* Iteration: Repeat the gradient calculation and update steps until convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-3.7806166769441725e-05,\n",
       " [-2.64888617180133,\n",
       "  -2.119108937441064,\n",
       "  -1.6952871499528512,\n",
       "  -1.356229719962281,\n",
       "  -1.0849837759698249,\n",
       "  -0.8679870207758599,\n",
       "  -0.6943896166206879,\n",
       "  -0.5555116932965503,\n",
       "  -0.4444093546372402,\n",
       "  -0.35552748370979215,\n",
       "  -0.2844219869678337,\n",
       "  -0.22753758957426698,\n",
       "  -0.1820300716594136,\n",
       "  -0.14562405732753086,\n",
       "  -0.11649924586202469,\n",
       "  -0.09319939668961975,\n",
       "  -0.0745595173516958,\n",
       "  -0.05964761388135664,\n",
       "  -0.04771809110508531,\n",
       "  -0.03817447288406825,\n",
       "  -0.0305395783072546,\n",
       "  -0.02443166264580368,\n",
       "  -0.019545330116642945,\n",
       "  -0.015636264093314357,\n",
       "  -0.012509011274651486,\n",
       "  -0.01000720901972119,\n",
       "  -0.008005767215776952,\n",
       "  -0.006404613772621562,\n",
       "  -0.00512369101809725,\n",
       "  -0.0040989528144778,\n",
       "  -0.00327916225158224,\n",
       "  -0.0026233298012657918,\n",
       "  -0.0020986638410126334,\n",
       "  -0.0016789310728101067,\n",
       "  -0.0013431448582480853,\n",
       "  -0.0010745158865984683,\n",
       "  -0.0008596127092787747,\n",
       "  -0.0006876901674230197,\n",
       "  -0.0005501521339384157,\n",
       "  -0.0004401217071507326,\n",
       "  -0.0003520973657205861,\n",
       "  -0.0002816778925764689,\n",
       "  -0.0002253423140611751,\n",
       "  -0.0001802738512489401,\n",
       "  -0.00014421908099915208,\n",
       "  -0.00011537526479932167,\n",
       "  -9.230021183945733e-05,\n",
       "  -7.384016947156586e-05,\n",
       "  -5.907213557725269e-05,\n",
       "  -4.7257708461802155e-05,\n",
       "  -3.7806166769441725e-05])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function f(x) = x^2\n",
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "# Derivative of f, f'(x) = 2x\n",
    "def df(x):\n",
    "    return 2*x\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "def sgd(initial_x, learning_rate, num_iterations):\n",
    "    x = initial_x\n",
    "    history = [x]\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        gradient = df(x)\n",
    "        x = x - learning_rate * gradient\n",
    "        history.append(x)\n",
    "        \n",
    "    return x, history\n",
    "\n",
    "# Parameters\n",
    "initial_x = np.random.uniform(-10, 10)  # Starting with a random guess between -10 and 10\n",
    "learning_rate = 0.1\n",
    "num_iterations = 50\n",
    "\n",
    "final_x, history = sgd(initial_x, learning_rate, num_iterations)\n",
    "\n",
    "final_x, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empirical Risk Explained\n",
    "\n",
    "Empirical risk in the context of machine learning and artificial intelligence refers to the measure of error of a hypothesis (or a learned model) on a specific dataset. Specifically, it measures the error on the training data that has been observed, as opposed to the true risk which measures the error on the entire distribution from which the training data is drawn.\n",
    "\n",
    "To explain further:\n",
    "\n",
    "True Risk: This represents the expected loss of a hypothesis (model) over the entire data distribution. It is the error rate we would get if we could test the hypothesis on all possible data points that could ever be drawn from the underlying distribution. Since this is typically infeasible in practice, we never really know the true risk.\n",
    "\n",
    "Empirical Risk: This is the average loss of the hypothesis over the sample dataset (often the training dataset). In other words, it is the observed error rate on the data we have at hand.\n",
    "\n",
    "In machine learning, we often operate under the Empirical Risk Minimization (ERM) principle, which aims to find a hypothesis (or model) that minimizes the empirical risk, with the hope that it will also have a low true risk. However, this isn't always guaranteed, especially if the training dataset isn't representative of the overall distribution, or if the model is too complex and overfits the training data.\n",
    "\n",
    "To help bridge the gap between empirical risk and true risk, various regularization techniques, cross-validation, and other model validation methods are used. The goal is to ensure that a model that performs well on the training data (low empirical risk) will also perform well on new, unseen data (low true risk)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function:\n",
    "A loss function, also known as a cost function or objective function, is a method to measure how far off a prediction is from the actual value. In machine learning, during the training phase, we use a loss function to represent the discrepancy between the predicted values and the true values. The aim is to minimize this discrepancy, or loss, to improve the model's accuracy.\n",
    "\n",
    "For instance, in regression problems where the goal is to predict a continuous value, the loss function might measure the difference between the predicted numeric value and the actual numeric value. In classification problems, on the other hand, the loss function measures the difference between the predicted class probabilities and the actual class labels.\n",
    "\n",
    "### Quadratic Loss Function:\n",
    "The quadratic loss function, often referred to as the mean squared error (MSE) for regression problems, is one of the most commonly used loss functions. It is defined as the average of the squared differences between the predicted values and the actual values. For a set of predictions $ \\hat{y_i} $ and actual values $ y_i $ for $ i = 1, 2, ..., n $, the quadratic loss function is:\n",
    "\n",
    "$$ L(y, \\hat{y}) = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2 $$\n",
    "\n",
    "Where:\n",
    "- $ y_i $ is the actual value for the ith data point.\n",
    "- $ \\hat{y_i} $ is the predicted value for the ith data point.\n",
    "- $ n $ is the number of data points in the dataset.\n",
    "\n",
    "The quadratic loss function penalizes large errors more heavily than small errors because of the squaring operation. This can be both an advantage and a disadvantage. On the upside, it leads the optimization process to correct larger errors more aggressively. On the downside, it can be overly sensitive to outliers since the squaring operation blows up the value of large errors.\n",
    "\n",
    "In practice, the choice of a loss function depends on the problem at hand, the nature of the data, and the specific requirements of the application. While the quadratic loss function is popular for regression, other loss functions like the absolute error (which does not square the differences) or the Huber loss (which is a combination of squared and absolute error) might be preferred in situations where robustness to outliers is critical.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Role of the Margin in Classifiers:\n",
    "\n",
    "When discussing classifiers, especially in the context of Support Vector Machines (SVMs) and linear classifiers, the margin plays a crucial role. The notation \\(a(x, w) = \\text{sign}\\langle x, w \\rangle\\) represents a linear classifier where $ a(x, w)$ gives the predicted class of a data point $x$ using weight vector $w$.\n",
    "\n",
    "The inner product $\\langle x, w \\rangle$ computes a weighted sum of the features in $x$,  and the sign of this sum determines the predicted class.\n",
    "\n",
    "1. **Definition**: \n",
    "   - The margin is the distance between the decision boundary (the hyperplane defined by $ \\langle x, w \\rangle = 0 $) and the closest data point(s) from either class. In the context of SVMs, these closest data points are known as support vectors. \n",
    "\n",
    "2. **Maximum Margin Principle**: \n",
    "   - The goal of some linear classifiers, especially SVMs, is to find the decision boundary that maximizes this margin. Intuitively, a larger margin indicates a more confident classification decision, as it implies that the decision boundary is as far away as possible from data points of either class. A classifier that achieves a larger margin is believed to have better generalization to unseen data.\n",
    "\n",
    "3. **Computation**: \n",
    "   - The margin, $m$, for a given weight vector $w$ can be computed as:\n",
    "     $$ m = \\frac{1}{\\|w\\|} $$\n",
    "   where $\\|w\\|$ is the norm (magnitude) of the weight vector. The inverse relationship implies that as the weight vector becomes smaller in magnitude, the margin becomes larger.\n",
    "\n",
    "4. **Robustness**: \n",
    "   - A decision boundary with a larger margin is often more robust to noise and variations in the data. Small perturbations in the data are less likely to cause misclassifications when the margin is larger.\n",
    "\n",
    "5. **Regularization**: \n",
    "   - Regularization techniques often aim to constrain the magnitude of the weight vector $w$. By doing so, they indirectly optimize for a larger margin, making the model less likely to overfit to the training data.\n",
    "\n",
    "6. **Hard vs. Soft Margin**: \n",
    "   - In scenarios where the data is linearly separable, we can find a decision boundary (or \"hard margin\") that perfectly separates the classes. However, in many real-world scenarios, the data is not perfectly separable. In such cases, a \"soft margin\" SVM is used, which allows some data points to be misclassified or to fall within the margin, in order to achieve a broader, more generalizable decision boundary.\n",
    "\n",
    "In summary, the margin is a critical concept in linear classification. It provides a geometric interpretation of the classifier's confidence and robustness. Maximizing the margin often leads to classifiers that generalize better to unseen data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Function:\n",
    "\n",
    "The sigmoid function is a special S-shaped curve used to map any input value to an output value between 0 and 1. It's particularly known for its application in artificial neural networks, especially for binary classification problems, due to its ability to work as an activation function.\n",
    "\n",
    "Mathematically, the sigmoid function is defined as:\n",
    "\n",
    "$$ \\sigma(z) = \\frac{1}{1 + e^{-z}} $$\n",
    "\n",
    "Where:\n",
    "- $ \\sigma(z) $ is the output after applying the sigmoid function.\n",
    "- $ e $ is the base of natural logarithms.\n",
    "- $ z $ is the input to the function.\n",
    "\n",
    "#### Properties:\n",
    "\n",
    "1. **Output Range**: Outputs values in the range (0, 1).\n",
    "2. **S-shaped Curve**: Characteristic S-shape.\n",
    "3. **Monotonicity**: Monotonically increasing function.\n",
    "4. **Saturation**: Can \"saturate\" at tail ends leading to the vanishing gradient problem.\n",
    "5. **Centered around 0.5**: At $ z = 0 $, it outputs 0.5.\n",
    "6. **Smooth Gradient**: Differentiable everywhere, allowing for gradient-based optimization.\n",
    "\n",
    "Although popular in earlier neural networks, other activation functions like the Rectified Linear Unit (ReLU) are often preferred in modern deep learning. However, the sigmoid is still frequently used in the output layer of binary classification networks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-ml-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
